{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bbc_news_archive.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNnALg/M2EyWrdvR0L7c1zT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UTKARSH4/bbc_news_archive/blob/main/bbc_news_archive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhsv8G3UbtLb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvVAzc76c731"
      },
      "source": [
        "## meta data\n",
        "data=[]\n",
        "with open('bbc-news-data.csv','r') as f:\n",
        "  for row in csv.reader(f):\n",
        "    data.append(row[0].split('\\t'))\n",
        "\n",
        "\n",
        "## content of data\n",
        "data_cont=[]\n",
        "with open('bbc-news-data.csv','r') as f:\n",
        "  for row in csv.reader(f):\n",
        "    data_cont.append(row[1:])   \n",
        "\n",
        "col=data[0]\n",
        "df = pd.DataFrame(data[1:],columns=col) \n",
        "\n",
        "\n",
        "for i in range(len(data)):\n",
        "  data_cont[i].insert(0, data[i][-1])\n",
        "    \n"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENPQLM1iiZOJ"
      },
      "source": [
        "del df['content']\n",
        "df['content_all']=data_cont[1:]\n",
        "#df=df['category','file','title','content_all']\n"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWuhL7hKCYHg"
      },
      "source": [
        "df['merged']=''\n",
        "for i in range(df.shape[0]):\n",
        "  df.merged[i] = ' '.join(df.iloc[i][3])"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbQ2NO23Bkhv",
        "outputId": "dc966d95-6d1c-4ad7-995b-af9e56c63553"
      },
      "source": [
        "df.merged[0]\n"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Quarterly profits at US media giant TimeWarne...\n",
              "1        The owners of embattled Russian oil giant Yuk...\n",
              "2        British Airways has blamed high fuel prices f...\n",
              "3        Shares in UK drinks and food firm Allied Dome...\n",
              "4        Japan's economy teetered on the brink of a te...\n",
              "                              ...                        \n",
              "1618     Internet TV has been talked about since the s...\n",
              "1619     Thousands of products and tens of thousands o...\n",
              "1620     Making games for future consoles will require...\n",
              "1621     A new European directive could put software w...\n",
              "1622     The man making sure US computer networks are ...\n",
              "Name: merged, Length: 1623, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l53ZRnTFrUlF"
      },
      "source": [
        "\n",
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X70Ir_oJ3CIQ"
      },
      "source": [
        "vocab_size = 100000\n",
        "embedding_dim = 16\n",
        "max_length = 1000 # Expected max_len is 120 a few cells down.\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_portion = .8"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-tUitQRPLdb"
      },
      "source": [
        "training_portion=0.8\n",
        "train_set=df.iloc[0:int(df.shape[0]*training_portion)]\n",
        "eval_set=df.iloc[int(df.shape[0]*training_portion)+1:-1]"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRnOoRT-3fhv"
      },
      "source": [
        "tokenizer_text =Tokenizer(oov_token=oov_tok)\n",
        "tokenizer_text.fit_on_texts(df.merged)\n",
        "word_index = tokenizer_text.word_index\n",
        "\n",
        "train_sequences = tokenizer_text.texts_to_sequences(train_set.merged)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "\n",
        "eval_sequences = tokenizer_text.texts_to_sequences(eval_set.merged)\n",
        "eval_padded = pad_sequences(eval_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep-G7zQq57AB"
      },
      "source": [
        "tokenizer_label =Tokenizer()\n",
        "tokenizer_label.fit_on_texts(df.category)\n",
        "label_index = tokenizer_text.word_index\n",
        "\n",
        "train_labels = np.array(tokenizer_label.texts_to_sequences(train_set.category))\n",
        "\n",
        "\n",
        "eval_labels = np.array(tokenizer_label.texts_to_sequences(eval_set.category))\n"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLYYBsSq9HZx",
        "outputId": "faeb63b6-36ed-4d77-a39f-8393ffac3b50"
      },
      "source": [
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 1000, 16)          1600000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 24)                408       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 150       \n",
            "=================================================================\n",
            "Total params: 1,600,558\n",
            "Trainable params: 1,600,558\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfxP-2Wb_3aF",
        "outputId": "d5b1702b-9d2c-459b-8184-150dea1bce3c"
      },
      "source": [
        "num_epochs = 30\n",
        "history = model.fit(train_padded, train_labels, epochs=num_epochs, validation_data=(eval_padded, eval_labels))"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "41/41 [==============================] - 2s 23ms/step - loss: 1.7715 - accuracy: 0.3156 - val_loss: 1.8720 - val_accuracy: 0.2229\n",
            "Epoch 2/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.6654 - accuracy: 0.3961 - val_loss: 2.1221 - val_accuracy: 0.2229\n",
            "Epoch 3/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.5195 - accuracy: 0.3841 - val_loss: 2.6055 - val_accuracy: 0.2786\n",
            "Epoch 4/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.4035 - accuracy: 0.4239 - val_loss: 3.1043 - val_accuracy: 0.2663\n",
            "Epoch 5/30\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.3307 - accuracy: 0.4727 - val_loss: 3.4820 - val_accuracy: 0.2601\n",
            "Epoch 6/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.2765 - accuracy: 0.5278 - val_loss: 3.7706 - val_accuracy: 0.2601\n",
            "Epoch 7/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.2029 - accuracy: 0.5732 - val_loss: 4.0094 - val_accuracy: 0.2508\n",
            "Epoch 8/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.1197 - accuracy: 0.6119 - val_loss: 4.2159 - val_accuracy: 0.2384\n",
            "Epoch 9/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.0335 - accuracy: 0.6721 - val_loss: 4.4143 - val_accuracy: 0.2291\n",
            "Epoch 10/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.9599 - accuracy: 0.7364 - val_loss: 4.5207 - val_accuracy: 0.2415\n",
            "Epoch 11/30\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.8811 - accuracy: 0.7383 - val_loss: 4.6920 - val_accuracy: 0.2322\n",
            "Epoch 12/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.7947 - accuracy: 0.7829 - val_loss: 4.8487 - val_accuracy: 0.1950\n",
            "Epoch 13/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.7253 - accuracy: 0.8055 - val_loss: 5.0273 - val_accuracy: 0.1610\n",
            "Epoch 14/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.6680 - accuracy: 0.8078 - val_loss: 5.0964 - val_accuracy: 0.1796\n",
            "Epoch 15/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.5884 - accuracy: 0.8349 - val_loss: 5.2198 - val_accuracy: 0.1796\n",
            "Epoch 16/30\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5253 - accuracy: 0.8667 - val_loss: 5.3662 - val_accuracy: 0.1610\n",
            "Epoch 17/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4929 - accuracy: 0.9372 - val_loss: 5.4270 - val_accuracy: 0.1858\n",
            "Epoch 18/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4208 - accuracy: 0.9165 - val_loss: 5.5796 - val_accuracy: 0.1486\n",
            "Epoch 19/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3826 - accuracy: 0.9849 - val_loss: 5.6742 - val_accuracy: 0.1548\n",
            "Epoch 20/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3439 - accuracy: 0.9856 - val_loss: 5.8067 - val_accuracy: 0.0805\n",
            "Epoch 21/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3000 - accuracy: 0.9957 - val_loss: 5.9734 - val_accuracy: 0.0774\n",
            "Epoch 22/30\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2787 - accuracy: 0.9923 - val_loss: 5.9424 - val_accuracy: 0.1022\n",
            "Epoch 23/30\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2441 - accuracy: 0.9949 - val_loss: 5.9985 - val_accuracy: 0.1610\n",
            "Epoch 24/30\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2054 - accuracy: 0.9965 - val_loss: 6.0639 - val_accuracy: 0.1548\n",
            "Epoch 25/30\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.1846 - accuracy: 0.9988 - val_loss: 6.1069 - val_accuracy: 0.1610\n",
            "Epoch 26/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1651 - accuracy: 0.9977 - val_loss: 6.3341 - val_accuracy: 0.0650\n",
            "Epoch 27/30\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.1462 - accuracy: 0.9990 - val_loss: 6.3317 - val_accuracy: 0.0898\n",
            "Epoch 28/30\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.1330 - accuracy: 0.9996 - val_loss: 6.4374 - val_accuracy: 0.0712\n",
            "Epoch 29/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1247 - accuracy: 0.9989 - val_loss: 6.4129 - val_accuracy: 0.0774\n",
            "Epoch 30/30\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1050 - accuracy: 0.9977 - val_loss: 6.4580 - val_accuracy: 0.0774\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}